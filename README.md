<p align="center">
  <img src="https://img.shields.io/badge/VORTEX-Cognitive_Defense_System-00FFB2?style=for-the-badge&labelColor=0A0A0A" alt="VORTEX Badge"/>
</p>

<h1 align="center">ğŸŒ€ VORTEX</h1>

<p align="center">
  <strong>Sistema Inteligente de Combate a Fake News com InteligÃªncia Artificial</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=white" alt="React"/>
  <img src="https://img.shields.io/badge/FastAPI-0.100+-009688?logo=fastapi&logoColor=white" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/PostgreSQL-16-4169E1?logo=postgresql&logoColor=white" alt="PostgreSQL"/>
  <img src="https://img.shields.io/badge/Gemini_AI-2.0_Flash-4285F4?logo=google&logoColor=white" alt="Gemini"/>
  <img src="https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white" alt="Docker"/>
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License"/>
</p>

<p align="center">
  <em>Detecte, analise e verifique notÃ­cias falsas automaticamente usando InteligÃªncia Artificial</em>
</p>

---

## ğŸ“– O Que Ã© o VORTEX?

O **VORTEX** (Verification & Observation of Real-Time EXploits) Ã© um sistema completo de defesa cognitiva contra desinformaÃ§Ã£o baseado em **RAG (Retrieval-Augmented Generation)**. Em termos simples:

1. ğŸ¤– O sistema **coleta notÃ­cias** automaticamente de portais confiÃ¡veis via RSS/scraping
2. ğŸ§  Usa **InteligÃªncia Artificial (Google Gemini 2.0 Flash)** para analisar cada notÃ­cia e identificar padrÃµes de fake news
3. ğŸ” Permite que **vocÃª cole qualquer texto ou afirmaÃ§Ã£o** e o sistema verifica se Ã© verdadeiro, falso ou inconclusivo
4. ğŸ“Š Mostra tudo em um **painel visual moderno** com estatÃ­sticas em tempo real

> **Pense no VORTEX como um "detector de mentiras digital"** â€” ele cruza informaÃ§Ãµes de fontes confiÃ¡veis para te dizer se aquela notÃ­cia do WhatsApp Ã© verdadeira ou nÃ£o.

---

## ğŸ¯ Funcionalidades Principais

### 1. ğŸ“° Coleta AutomÃ¡tica de NotÃ­cias (Database-Driven)

O sistema busca notÃ­cias automaticamente em **6 fontes confiÃ¡veis** brasileiras usando **155 feeds RSS** armazenados no PostgreSQL:

| Fonte | Feeds | Exemplos |
|-------|-------|----------|
| **G1** (Globo) | 69 feeds | Brasil, Mundo, Tecnologia, Estados, Cidades |
| **Folha de S.Paulo** | 44 feeds | PolÃ­tica, Mercado, Cotidiano, F5, Ilustrada |
| **UOL** | 28 feeds | NotÃ­cias, Tecnologia, Esportes, Vestibular |
| **BBC Brasil** | 12 feeds | Brasil, Internacional, Economia, CiÃªncia |
| **CNN Brasil** | 1 feed | News Sitemap |
| **EstadÃ£o** | 1 feed | PolÃ­tica |

**Arquitetura de Coleta:**
- âœ… **Database-driven**: URLs armazenadas em PostgreSQL (`rss_feed` table)
- âœ… **Parallel scraping**: Processa 5 URLs simultaneamente (asyncio.gather)
- âœ… **Batch commits**: Salva mÃºltiplos artigos por transaÃ§Ã£o
- âœ… **DeduplicaÃ§Ã£o automÃ¡tica**: URL com constraint `UNIQUE` no banco
- âœ… **Filtro de qualidade**: TÃ­tulo â‰¥10 chars, conteÃºdo â‰¥300 chars
- âœ… **Rate limiting**: 0.5s delay entre batches para nÃ£o sobrecarregar servidores

**Capacidade atual:**
- ğŸ”¢ **8.673+ artigos** coletados (exemplo de coleta real)
- ğŸ“¡ **155 feeds RSS** ativos
- ğŸ”„ **Coleta automÃ¡tica** a cada 1 hora (configurÃ¡vel via `COLLECT_INTERVAL_HOURS`)
- âš¡ **Processamento paralelo** - 5 URLs simultÃ¢neas
- ğŸ¯ **Taxa de sucesso** ~76% (23% rejeitados por qualidade)

### 2. ğŸ¤– AnÃ¡lise com InteligÃªncia Artificial (Phase 2)

Cada artigo coletado Ã© analisado pelo **Google Gemini 2.0 Flash**, que identifica:

- âš ï¸ **Linguagem sensacionalista** (tÃ­tulos exagerados, alarmistas)
- ğŸ£ **Clickbait** (tÃ­tulos enganosos para gerar cliques)
- ğŸ˜¡ **ManipulaÃ§Ã£o emocional** (apelar para medo, raiva, indignaÃ§Ã£o)
- ğŸ“‰ **AusÃªncia de fontes** (afirmaÃ§Ãµes sem dados ou referÃªncias)
- ğŸ”„ **InconsistÃªncias** (informaÃ§Ãµes que se contradizem)

**Resultado estruturado:**
```json
{
  "is_fake": boolean,
  "confidence_score": 0.0-1.0,
  "reasoning": "ExplicaÃ§Ã£o tÃ©cnica...",
  "detected_markers": ["sensacionalismo", "falta de fontes"],
  "scores": {
    "factual_consistency": 0-10,
    "linguistic_bias": 0-10,
    "sensationalism": 0-10,
    "source_credibility": 0-10
  }
}
```

### 3. ğŸ” IndexaÃ§Ã£o SemÃ¢ntica (Phase 3)

Usa **pgvector** (extensÃ£o do PostgreSQL) para busca por similaridade:

- ğŸ“Š **Embeddings**: Vetores de 768 dimensÃµes via `text-embedding-004`
- ğŸ” **Busca semÃ¢ntica**: Cosine distance search no PostgreSQL
- âš¡ **Performance**: Ãndice HNSW para buscas rÃ¡pidas
- ğŸ¯ **PrecisÃ£o**: Encontra artigos relevantes mesmo sem palavras exatas

### 4. âœ… VerificaÃ§Ã£o de Fatos (Phase 4 - RAG)

VocÃª pode verificar **qualquer afirmaÃ§Ã£o** ou **artigo completo**:

**Fluxo de verificaÃ§Ã£o:**
1. UsuÃ¡rio submete afirmaÃ§Ã£o: *"O governo vai taxar o PIX"*
2. Sistema gera embedding da afirmaÃ§Ã£o (768-dim vector)
3. Busca semÃ¢ntica retorna top 5 artigos mais similares (pgvector)
4. Gemini 2.0 Flash compara afirmaÃ§Ã£o com evidÃªncias
5. Retorna veredicto estruturado:

```
ğŸŸ¢ [VERDADEIRO]           - Confirmado por evidÃªncias
ğŸ”´ [FALSO]                - Contradiz evidÃªncias
ğŸŸ¡ [PARCIALMENTE VERDADEIRO] - Parcialmente correto
âšª [INCONCLUSIVO]         - Sem evidÃªncias suficientes
```

### 5. ğŸ–¥ï¸ Dashboard Interativo

Interface web moderna construÃ­da com **React 18 + TypeScript**, tema escuro e responsiva:

- ğŸ“Š **EstatÃ­sticas em tempo real** â€” Artigos coletados, analisados, verificaÃ§Ãµes
- ğŸ“œ **HistÃ³rico de verificaÃ§Ãµes** â€” Todas as verificaÃ§Ãµes anteriores
- ğŸŸ¢ **Status das fontes** â€” Monitoramento de saÃºde (HTTP 200)
- â° **AutomaÃ§Ã£o** â€” PrÃ³xima execuÃ§Ã£o do scheduler
- ğŸ” **Login seguro** â€” AutenticaÃ§Ã£o via Google (Clerk)

---

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VORTEX SYSTEM                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”‚                                            â”‚
â”‚  ğŸŒ FRONTEND         â”‚  âš™ï¸ BACKEND                               â”‚
â”‚  React + TypeScript  â”‚  Python 3.11 + FastAPI                     â”‚
â”‚  Porta 80 (nginx)    â”‚  Porta 8420                                â”‚
â”‚                      â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Dashboard     â”‚â”€â”€â”€â”€â”€â–¶â”‚  API REST                            â”‚ â”‚
â”‚  â”‚  Login/Auth    â”‚  â”‚  â”‚  /api/verify  (fact-check)           â”‚ â”‚
â”‚  â”‚  EstatÃ­sticas  â”‚  â”‚  â”‚  /api/analyze (run phase 2)          â”‚ â”‚
â”‚  â”‚  HistÃ³rico     â”‚  â”‚  â”‚  /api/status  (system stats)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  /api/history (past verifications)   â”‚ â”‚
â”‚                      â”‚  â”‚  /api/sources (source health)        â”‚ â”‚
â”‚                      â”‚  â”‚  /api/quality (data quality)         â”‚ â”‚
â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚             â”‚                              â”‚
â”‚                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                      â”‚  â”‚  ğŸ¤– Motor de IA (4 Phases)          â”‚ â”‚
â”‚                      â”‚  â”‚                                      â”‚ â”‚
â”‚                      â”‚  â”‚  Phase 1: Collector (RSS/Scraping)  â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ 155 RSS feeds from PostgreSQL    â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Parallel scraping (5 async)      â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Batch commits                    â”‚ â”‚
â”‚                      â”‚  â”‚                                      â”‚ â”‚
â”‚                      â”‚  â”‚  Phase 2: Analyzer (Gemini AI)      â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Fake news markers detection      â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Quality scores (0-10)            â”‚ â”‚
â”‚                      â”‚  â”‚                                      â”‚ â”‚
â”‚                      â”‚  â”‚  Phase 3: Indexer (pgvector)        â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Generate 768-dim embeddings      â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Store in PostgreSQL              â”‚ â”‚
â”‚                      â”‚  â”‚                                      â”‚ â”‚
â”‚                      â”‚  â”‚  Phase 4: Verifier (RAG)            â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Semantic search (cosine dist.)   â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ LLM cross-referencing            â”‚ â”‚
â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                                            â”‚
â”‚                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                      â”‚  â”‚  ğŸ“Š PostgreSQL 16 + pgvector         â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Articles (title, content, url)    â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Embeddings (768-dim vectors)      â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Analysis (AI verdicts)            â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Verifications (fact-checks)       â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ RSS Feeds (155 URLs)              â”‚ â”‚
â”‚                      â”‚  â”‚  â€¢ Sources (6 news outlets)          â”‚ â”‚
â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                                            â”‚
â”‚                      â”‚  â° APScheduler (Background Jobs)          â”‚
â”‚                      â”‚  â€¢ Collect every 1h (configurable)        â”‚
â”‚                      â”‚  â€¢ Source monitoring every 1h             â”‚
â”‚                      â”‚                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ³ Docker Compose (3 containers: backend, frontend, vortex-db)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ› ï¸ Stack TecnolÃ³gica

| Camada | Tecnologia | Para QuÃª? |
|--------|-----------|-----------|
| **Frontend** | React 18 + TypeScript + Vite | Interface do usuÃ¡rio |
| **Estilo** | CSS moderno (tema escuro) | Visual premium |
| **AutenticaÃ§Ã£o** | Clerk (Google OAuth) | Login seguro |
| **Backend** | Python 3.11 + FastAPI | API e lÃ³gica do servidor |
| **IA Generativa** | Google Gemini 2.0 Flash | AnÃ¡lise de fake news + RAG |
| **Embeddings** | text-embedding-004 (Gemini) | Transformar texto em vetores (768-dim) |
| **Banco de Dados** | PostgreSQL 16 + pgvector | Armazenamento + busca semÃ¢ntica |
| **Banco Vetorial** | pgvector extension | Cosine distance search (HNSW index) |
| **ORM** | SQLModel + AsyncSession | Queries assÃ­ncronas |
| **Scraping** | BeautifulSoup4 + httpx | Coleta de notÃ­cias |
| **Agendamento** | APScheduler | AutomaÃ§Ã£o de tarefas |
| **ContainerizaÃ§Ã£o** | Docker + Docker Compose | Deploy simplificado |
| **Servidor Web** | Nginx (Alpine) | Servir frontend em produÃ§Ã£o |
| **Rate Limiting** | SlowAPI | ProteÃ§Ã£o contra abuso |

---

## ğŸš€ Como Instalar

### **PrÃ©-requisitos**

Antes de comeÃ§ar, vocÃª vai precisar ter instalado:

- [Docker](https://docs.docker.com/get-docker/) e [Docker Compose](https://docs.docker.com/compose/install/)
- [Git](https://git-scm.com/downloads)
- Uma chave de API do **Google Gemini** (grÃ¡tis): [Obtenha aqui](https://aistudio.google.com/app/apikey)
- Uma conta no **Clerk** para autenticaÃ§Ã£o: [Crie aqui](https://dashboard.clerk.com)

---

### **Deploy com Docker (Recomendado)** ğŸ³

#### Passo 1: Clone o RepositÃ³rio

```bash
git clone https://github.com/pomboid/kill-fake-news.git
cd kill-fake-news
```

#### Passo 2: Configure as VariÃ¡veis de Ambiente

**Backend** (`.env` na raiz):
```bash
cp .env.production.example .env
nano .env
```

Preencha:
```env
# ObrigatÃ³rio â€” Chave da API Gemini
GEMINI_API_KEY=sua_chave_gemini_aqui

# API Key interna (para proteger endpoints)
VORTEX_API_KEY=sua_chave_secreta_aqui

# ConfiguraÃ§Ãµes do scheduler
COLLECT_INTERVAL_HOURS=1        # Coleta automÃ¡tica a cada 1 hora
SOURCE_CHECK_INTERVAL_HOURS=1   # Monitoramento de fontes a cada 1 hora
LOG_LEVEL=INFO

# PostgreSQL (jÃ¡ configurado no docker-compose.yml)
DATABASE_URL=postgresql+asyncpg://vortex:vortex_password@vortex-db:5432/vortex_db

# CORS
ALLOWED_ORIGINS=http://localhost,http://127.0.0.1,http://SEU_IP

# Chave do Clerk (para Docker Compose build args)
VITE_CLERK_PUBLISHABLE_KEY=pk_test_sua_chave_clerk_aqui
VITE_API_URL=http://SEU_IP:8420
```

**Frontend** (`frontend/.env`):
```bash
nano frontend/.env
```

Preencha:
```env
VITE_CLERK_PUBLISHABLE_KEY=pk_test_sua_chave_clerk_aqui
VITE_API_URL=http://SEU_IP:8420
```

> âš ï¸ **IMPORTANTE:** Substitua `SEU_IP` pelo IP do seu servidor (ex: `192.168.1.100` ou `localhost`).

#### Passo 3: Suba os Containers

```bash
docker compose up -d --build
```

Aguarde ~60 segundos para o build completar.

#### Passo 4: Popular o Banco com RSS Feeds

```bash
# Criar tabelas e popular feeds
docker compose exec backend python scripts/seed_rss_feeds.py
```

Isso vai criar 6 fontes e 155 feeds RSS no PostgreSQL.

#### Passo 5: Coletar Primeiros Artigos

```bash
# Coletar artigos de todas as fontes (pode demorar ~30min-1h)
docker compose exec backend python main.py collect

# OU com limite para teste rÃ¡pido:
docker compose exec backend python main.py collect --limit 50
```

#### Passo 6: Verifique

```bash
# Ver se os 3 containers estÃ£o rodando
docker ps

# Deve mostrar:
# vortex-backend   (porta 8420)
# vortex-frontend  (porta 80)
# vortex-db        (porta 5432, interna)

# Ver status do sistema
docker compose exec backend python main.py status
```

#### Passo 7: Acesse

```
Frontend (Interface): http://SEU_IP
Backend (API):        http://SEU_IP:8420
API Docs:             http://SEU_IP:8420/docs
```

---

### **InstalaÃ§Ã£o Local (Desenvolvimento)** ğŸ’»

Para quem quer desenvolver e modificar o cÃ³digo:

#### Backend

```bash
# Clone o projeto
git clone https://github.com/pomboid/kill-fake-news.git
cd kill-fake-news

# Crie e ative um ambiente virtual
python -m venv venv
source venv/bin/activate     # Linux/Mac
# ou
venv\Scripts\activate        # Windows

# Instale as dependÃªncias
pip install -r requirements.txt

# Configure PostgreSQL local
# Instale PostgreSQL 16+ com extensÃ£o pgvector
createdb vortex_db
psql vortex_db -c "CREATE EXTENSION vector;"

# Configure variÃ¡veis de ambiente
cp .env.production.example .env
nano .env  # Adicione GEMINI_API_KEY e DATABASE_URL

# Popular feeds
python scripts/seed_rss_feeds.py

# Rode o servidor
uvicorn server:app --host 0.0.0.0 --port 8420 --reload
```

#### Frontend

```bash
cd frontend

# Instale as dependÃªncias
npm install

# Configure variÃ¡veis de ambiente
nano .env
# Adicione:
# VITE_CLERK_PUBLISHABLE_KEY=pk_test_sua_chave
# VITE_API_URL=http://localhost:8420

# Rode o frontend (desenvolvimento)
npm run dev
# Acesse: http://localhost:5173
```

---

## ğŸ“– Como Usar

### Via Dashboard Web (Interface Visual)

1. Acesse `http://SEU_IP` no navegador
2. FaÃ§a login com sua conta Google
3. **Aguarde as fases 2 e 3** (primeira vez):
   ```bash
   # Fase 2: Analisar artigos com IA (pode demorar)
   docker compose exec backend python main.py analyze --limit 100

   # Fase 3: Indexar (criar embeddings)
   docker compose exec backend python main.py index
   ```
4. Use o campo **"Cortex Verification Engine"** para verificar afirmaÃ§Ãµes:
   - Cole uma notÃ­cia ou afirmaÃ§Ã£o (atÃ© 10.000 caracteres)
   - Clique em **"Run Verification"**
   - Veja o resultado: **Verdadeiro**, **Falso** ou **Inconclusivo**
5. Monitore as **estatÃ­sticas** e **fontes** na dashboard

### Via CLI (Linha de Comando)

```bash
# ğŸ“Š Ver status do sistema
python main.py status

# ğŸ“° FASE 1: Coletar notÃ­cias de todas as fontes
python main.py collect                  # Sem limite (coleta tudo)
python main.py collect --limit 100      # Com limite

# ğŸ§  FASE 2: Analisar artigos com IA (cuidado com cota da API)
python main.py analyze --limit 50       # Analisa 50 artigos nÃ£o analisados

# ğŸ” FASE 3: Indexar no banco vetorial (gerar embeddings)
python main.py index

# âœ… FASE 4: Verificar uma afirmaÃ§Ã£o
python main.py verify "O governo vai taxar o PIX"

# ğŸ”„ Pipeline completo (coleta + anÃ¡lise + indexaÃ§Ã£o)
python main.py full-pipeline

# ğŸ“œ Ver histÃ³rico de verificaÃ§Ãµes
python main.py history --limit 10

# ğŸ“Š Ver qualidade da base de dados
python main.py quality

# ğŸŒ± Popular feeds RSS no banco
python main.py seed-feeds
```

### Via API REST

```bash
# âœ… Verificar uma afirmaÃ§Ã£o (Phase 4)
curl -X POST http://SEU_IP:8420/api/verify \
  -H "Content-Type: application/json" \
  -d '{"claim": "Vacinas causam autismo"}'

# ğŸ“Š Status do sistema
curl http://SEU_IP:8420/api/status

# ğŸ§  Rodar anÃ¡lise em batch (Phase 2)
curl -X POST http://SEU_IP:8420/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"limit": 50}'

# ğŸ“œ HistÃ³rico de verificaÃ§Ãµes
curl http://SEU_IP:8420/api/history

# ğŸ“Š Qualidade da base de dados
curl http://SEU_IP:8420/api/quality

# ğŸŸ¢ Status das fontes (online/offline)
curl http://SEU_IP:8420/api/sources

# ğŸ“° Ãšltimas notÃ­cias coletadas
curl http://SEU_IP:8420/api/news?limit=20
```

> ğŸ“š **DocumentaÃ§Ã£o completa da API** disponÃ­vel em: `http://SEU_IP:8420/docs`

---

## ğŸ“ Estrutura do Projeto

```
kill-fake-news/
â”‚
â”œâ”€â”€ ğŸŒ frontend/                   # Interface do UsuÃ¡rio (React)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.tsx         # Barra de navegaÃ§Ã£o
â”‚   â”‚   â”‚   â”œâ”€â”€ StatsGrid.tsx      # Cards de estatÃ­sticas
â”‚   â”‚   â”‚   â”œâ”€â”€ VerifyForm.tsx     # Motor de verificaÃ§Ã£o
â”‚   â”‚   â”‚   â”œâ”€â”€ HistoryList.tsx    # HistÃ³rico de verificaÃ§Ãµes
â”‚   â”‚   â”‚   â”œâ”€â”€ SchedulerInfo.tsx  # Info de automaÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ SourcesList.tsx    # Lista de fontes
â”‚   â”‚   â”œâ”€â”€ pages/                 # PÃ¡ginas da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ App.tsx                # Componente principal
â”‚   â”‚   â””â”€â”€ main.tsx               # Entry point
â”‚   â”œâ”€â”€ Dockerfile                 # Build do frontend (Node â†’ Nginx)
â”‚   â”œâ”€â”€ package.json               # DependÃªncias JavaScript
â”‚   â””â”€â”€ .env.example               # Template de variÃ¡veis
â”‚
â”œâ”€â”€ âš™ï¸ core/                       # ConfiguraÃ§Ãµes do Sistema
â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ã£o centralizada
â”‚   â”œâ”€â”€ database.py                # ConexÃ£o PostgreSQL + AsyncSession
â”‚   â”œâ”€â”€ sql_models.py              # SQLModel schemas (Article, Source, etc.)
â”‚   â”œâ”€â”€ rate_limits.py             # Limites da API Gemini
â”‚   â”œâ”€â”€ logging_config.py          # ConfiguraÃ§Ã£o de logs
â”‚   â””â”€â”€ ui.py                      # Interface CLI
â”‚
â”œâ”€â”€ ğŸ§  modules/                    # MÃ³dulos de Processamento
â”‚   â”œâ”€â”€ intelligence/              # Coleta de notÃ­cias
â”‚   â”‚   â””â”€â”€ collector.py           # RSS/Scraping engine (parallel)
â”‚   â”œâ”€â”€ analysis/                  # AnÃ¡lise IA
â”‚   â”‚   â””â”€â”€ detector.py            # Gemini fake news detector
â”‚   â””â”€â”€ detection/                 # VerificaÃ§Ã£o RAG
â”‚       â””â”€â”€ verification_engine.py # pgvector + Gemini RAG
â”‚
â”œâ”€â”€ ğŸ“œ scripts/                    # Scripts utilitÃ¡rios
â”‚   â””â”€â”€ seed_rss_feeds.py          # Popular feeds no PostgreSQL
â”‚
â”œâ”€â”€ ğŸ§ª tests/                      # Testes Automatizados
â”‚
â”œâ”€â”€ ğŸ“„ server.py                   # API FastAPI (backend)
â”œâ”€â”€ ğŸ“„ scheduler.py                # Agendador de tarefas (APScheduler)
â”œâ”€â”€ ğŸ“„ main.py                     # CLI principal (argparse)
â”œâ”€â”€ ğŸ³ Dockerfile                  # Build do backend
â”œâ”€â”€ ğŸ³ docker-compose.yml          # OrquestraÃ§Ã£o (backend + frontend + db)
â”œâ”€â”€ ğŸ“‹ requirements.txt            # DependÃªncias Python
â””â”€â”€ ğŸ“– README.md                   # Este arquivo
```

---

## ğŸ—„ï¸ Schema do Banco de Dados (PostgreSQL)

```sql
-- Tabela de fontes de notÃ­cias
CREATE TABLE source (
  id SERIAL PRIMARY KEY,
  name VARCHAR UNIQUE NOT NULL,        -- Ex: "G1", "Folha"
  display_name VARCHAR NOT NULL,
  website_url VARCHAR NOT NULL,
  status VARCHAR DEFAULT 'online',
  last_checked TIMESTAMP,
  is_active BOOLEAN DEFAULT true
);

-- Tabela de feeds RSS
CREATE TABLE rss_feed (
  id SERIAL PRIMARY KEY,
  source_id INTEGER REFERENCES source(id),
  feed_url VARCHAR UNIQUE NOT NULL,
  feed_type VARCHAR DEFAULT 'rss2',  -- rss2, atom, sitemap
  category VARCHAR,                   -- Ex: "Tecnologia", "PolÃ­tica"
  is_active BOOLEAN DEFAULT true,
  last_fetched TIMESTAMP,
  fetch_count INTEGER DEFAULT 0,
  error_count INTEGER DEFAULT 0,
  last_error TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Tabela de artigos coletados
CREATE TABLE article (
  id SERIAL PRIMARY KEY,
  title VARCHAR NOT NULL,
  subtitle VARCHAR,
  url VARCHAR UNIQUE NOT NULL,       -- Unique constraint (deduplicaÃ§Ã£o)
  content TEXT NOT NULL,
  author VARCHAR NOT NULL,
  published_at TIMESTAMP,
  created_at TIMESTAMP NOT NULL,
  embedding VECTOR(768),             -- pgvector: 768-dimensional
  source_id INTEGER REFERENCES source(id)
);

CREATE INDEX ON article USING HNSW (embedding vector_cosine_ops);

-- Tabela de anÃ¡lises IA (Phase 2)
CREATE TABLE analysis (
  id SERIAL PRIMARY KEY,
  article_id INTEGER REFERENCES article(id) UNIQUE,
  is_fake BOOLEAN NOT NULL,
  confidence FLOAT NOT NULL,
  reasoning TEXT NOT NULL,
  markers JSON,                      -- ["sensacionalismo", "falta de fontes"]
  scores JSON,                       -- {"factual": 7, "bias": 3, ...}
  analyzed_at TIMESTAMP NOT NULL
);

-- Tabela de verificaÃ§Ãµes (Phase 4)
CREATE TABLE verification (
  id SERIAL PRIMARY KEY,
  user_id VARCHAR,
  claim TEXT NOT NULL,
  verdict VARCHAR NOT NULL,          -- [VERDADEIRO], [FALSO], etc.
  confidence FLOAT NOT NULL,
  evidence JSON,                     -- [article_ids]
  created_at TIMESTAMP NOT NULL
);
```

---

## ğŸ³ Comandos Docker Ãšteis

```bash
# ğŸ“Š Ver containers rodando
docker ps

# ğŸ“œ Ver logs do backend
docker compose logs backend --tail 50 -f

# ğŸ“œ Ver logs do frontend
docker compose logs frontend --tail 50 -f

# ğŸ“œ Ver logs do PostgreSQL
docker compose logs vortex-db --tail 50 -f

# ğŸ”„ Atualizar apÃ³s mudanÃ§as no cÃ³digo
git pull origin main
docker compose down
docker compose up -d --build

# ğŸ”„ Rebuild apenas backend
docker compose up -d --build backend

# â¹ï¸ Parar tudo
docker compose down

# ğŸ—‘ï¸ Limpar tudo (âš ï¸ APAGA DADOS)
docker compose down -v
docker system prune -af

# ğŸ’¾ Backup do banco
docker compose exec vortex-db pg_dump -U vortex vortex_db > backup.sql

# ğŸ“¥ Restaurar backup
cat backup.sql | docker compose exec -T vortex-db psql -U vortex vortex_db

# ğŸš Entrar no container backend (debug)
docker compose exec backend bash

# ğŸš Acessar PostgreSQL
docker compose exec vortex-db psql -U vortex -d vortex_db
```

---

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Intervalo de Coleta

Edite `.env`:
```env
COLLECT_INTERVAL_HOURS=1   # Coletar a cada 1 hora
SOURCE_CHECK_INTERVAL_HOURS=1  # Monitorar fontes a cada 1 hora
```

Reinicie o backend:
```bash
docker compose restart backend
```

### Adicionar Novas Fontes RSS

1. Adicione a fonte em `scripts/seed_rss_feeds.py`
2. Execute:
```bash
docker compose exec backend python scripts/seed_rss_feeds.py
```

### Melhorar Seletores de Scraping

Edite `modules/intelligence/collector.py` â†’ `DOMAIN_MAP`:

```python
DOMAIN_MAP = {
    "exemplo.com.br": {
        "t": "h1.titulo",           # Seletor CSS do tÃ­tulo
        "s": "h2.subtitulo",        # Seletor CSS do subtÃ­tulo
        "b": "div.corpo-texto",     # Seletor CSS do body
        "p": "p.paragrafo"          # Seletor CSS dos parÃ¡grafos
    }
}
```

---

## âš ï¸ LimitaÃ§Ãµes e Avisos

| LimitaÃ§Ã£o | Detalhe |
|-----------|---------|
| **Free Tier Gemini** | ~1.500 requisiÃ§Ãµes/dia no plano gratuito. Suficiente para uso moderado. |
| **PrecisÃ£o da IA** | Nenhuma IA Ã© 100% precisa. Sempre verifique fontes primÃ¡rias. |
| **Idioma** | Otimizado para **PortuguÃªs Brasileiro**. |
| **Fontes** | Limitado Ã s fontes com RSS feeds pÃºblicos. Novas podem ser adicionadas. |
| **Embeddings** | Qualidade depende da base de dados. Mais artigos = mais precisÃ£o. |
| **Primeira coleta** | Pode demorar 30min-1h para coletar ~8.000 artigos na primeira vez. |

---

## ğŸ“ˆ Performance e Escalabilidade

| MÃ©trica | Valor |
|---------|-------|
| **Artigos coletados** | 8.673+ (exemplo real) |
| **Taxa de coleta** | ~150-200 artigos/minuto (5 paralelos) |
| **Tamanho do banco** | ~35 MB para 8.673 artigos |
| **Taxa de sucesso** | ~76% (23% rejeitados por qualidade) |
| **Busca semÃ¢ntica** | <100ms (pgvector HNSW index) |
| **API Gemini** | 2s rate limit entre anÃ¡lises (cota gratuita) |

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga estes passos:

1. ğŸ´ FaÃ§a um **fork** do projeto
2. ğŸŒ¿ Crie uma branch (`git checkout -b feature/MinhaFeature`)
3. ğŸ’¾ Commit suas mudanÃ§as (`git commit -m 'feat: adiciona MinhaFeature'`)
4. ğŸ“¤ Push para a branch (`git push origin feature/MinhaFeature`)
5. ğŸ”€ Abra um **Pull Request**

---

## ğŸŒŸ Roadmap Futuro

- [x] âœ… MigraÃ§Ã£o para PostgreSQL + pgvector
- [x] âœ… Database-driven RSS feeds (155 feeds)
- [x] âœ… Parallel scraping com asyncio
- [x] âœ… Batch commits e deduplicaÃ§Ã£o
- [ ] ğŸŒ Suporte a mÃºltiplos idiomas
- [ ] ğŸ’¬ IntegraÃ§Ã£o com Telegram e WhatsApp
- [ ] â­ Sistema de reputaÃ§Ã£o de fontes (consenso multi-fonte)
- [ ] ğŸ“ˆ Dashboard analytics avanÃ§ado
- [ ] ğŸ”Œ ExtensÃ£o para navegadores (Chrome/Firefox)
- [ ] ğŸ“± Aplicativo mobile (React Native)
- [ ] ğŸ”— Google Fact Check API integration
- [ ] ğŸ¯ Aumento de fontes (R7, MetrÃ³poles, etc.)

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a **MIT**. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ†˜ Suporte e Contato

- ğŸ“§ **Issues**: [GitHub Issues](https://github.com/pomboid/kill-fake-news/issues)
- ğŸ’¼ **LinkedIn**: [Weversson Vital](https://www.linkedin.com/in/weversson-vital/) | [Vitor Benedett Caldas](https://www.linkedin.com/in/vitorbenedettcaldas/)

---

<p align="center">
  <strong>Desenvolvido com ğŸ’š por Weversson Vital e Vitor Benedett Caldas</strong>
  <br/>
  <em>Â© 2026 VORTEX Cognitive Defense System. Combatendo Fake News com Tecnologia.</em>
</p>
